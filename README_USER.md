# НТО ИИ 2025–2026: Решение для второго этапа олимпиады

Данное решение создано на основе бейзлайна, который я постепенно дополнял, изучал и улучшал, применяя собственные идеи и методы.

---

## Старт работы

Все началось с запуска бейзлайна.
Я изменил `random_state`, загрузил результат в ODS для проверки работоспособности и оценки исходного скора. После этого начал менять различные параметры: количество итераций, точку остановки (*early stopping*), процент разделения на тренировочные и валидационные данные.

Эти изменения дали небольшой прирост. В течение нескольких дней я экспериментировал с метриками и параллельно писал скрипт для построения графиков, чтобы лучше понять структуру данных.

---

## Анализ данных и ключевой инсайт

Проанализировав графики, я начал изучать, какие признаки действительно влияют на модель.
В какой-то момент стало ясно, что **признак “язык 119” является почти единственным значимым**, а остальные создают лишний шум. После его выделения и правильной обработки я получил первый ощутимый прирост - **скор около 0.766**.

---

## Эксперименты с признаками

Позже я решил попробовать создавать дополнительные признаки, которые могли бы улучшить обучение модели.
Однако из-за усталости (совмещение работы и учебы) некоторые признаки получились сырыми - и один из них вызвал **серьезную утечку данных**, что полностью испортило результаты.

После этого я удалил весь написанный код и перешел к экспериментам по снижению шума. Но ни один метод не давал улучшений - метрики только падали. Тогда я понял, что текущие сырые данные не позволяют построить устойчивую базу для улучшения модели.

---

## Работа с конфигурацией модели

Я приступил к настройке конфига: изменял различные параметры, убирал лишние, добавлял новые.
Эти действия давали лишь минимальные изменения, **но без реального прироста в качестве**.

---

## Кризис и ключевой прорыв

На фоне усталости у меня начало появляться легкое выгорание. Я стал смотреть различные видео о языковых моделях, читать статьи на Хабре и в других источниках.

Будучи примерно на **65-м месте**, я наткнулся на материалы о различных *“целях обучения”* модели. После этого решил попробовать минимизировать **L1-ошибку** с помощью `regression_l1`.

Этот шаг дал значительный прирост: итоговый скор поднялся до **0.77+**.

Я хотел продолжить эксперименты, но к этому моменту потратил слишком много попыток впустую, и страх потерять результат заставил загружать решения в ODS максимально осторожно. Из-за этого времени на доработку уже не хватило.

---

## Итоги и планы к финалу

По итогам работы я выделил для себя несколько важных моментов, которые пригодятся в финале.
Стало ясно, что потребуется серьезная подготовка - как минимум **3 месяца интенсивной работы**, чтобы войти в число призеров или победителей олимпиады.

